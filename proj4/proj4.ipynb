{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, glob, os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms 4.289607529882952\n",
      "K\n",
      " [[4.21492395e+03 0.00000000e+00 3.17479184e+03]\n",
      " [0.00000000e+00 3.97244329e+03 1.55372480e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "dist [-0.44676877  1.47553326  0.00669606  0.05712767 -1.51373905]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMG_DIR=\"calibration\"\n",
    "OUT=\"calibration_output/calib_aruco.npz\"\n",
    "os.makedirs(os.path.dirname(OUT),exist_ok=True)\n",
    "\n",
    "tag=0.06\n",
    "d=cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "p=cv2.aruco.DetectorParameters()\n",
    "\n",
    "if hasattr(cv2.aruco,\"ArucoDetector\"):\n",
    "    det=cv2.aruco.ArucoDetector(d,p)\n",
    "    def detect(im): return det.detectMarkers(im)\n",
    "else:\n",
    "    def detect(im): return cv2.aruco.detectMarkers(im,d,parameters=p)\n",
    "\n",
    "paths=sorted(glob.glob(os.path.join(IMG_DIR,\"*.jpeg\")))\n",
    "\n",
    "\n",
    "obj=np.array([[0,0,0],[tag,0,0],[tag,tag,0],[0,tag,0]],np.float32)\n",
    "objl=[];imgl=[]\n",
    "sz=None;n=0\n",
    "\n",
    "for pth in paths:\n",
    "    im=cv2.imread(pth)\n",
    "    if im is None: continue\n",
    "    if sz is None: sz=(im.shape[1],im.shape[0])\n",
    "    c,i,_=detect(im)\n",
    "    if i is None or len(c)==0: continue\n",
    "    u=c[0].reshape(4,2).astype(np.float32)\n",
    "    imgl.append(u); objl.append(obj.copy()); n+=1\n",
    "\n",
    "r,K,dist,_,_=cv2.calibrateCamera(objl, imgl, sz, None, None)\n",
    "print(\"rms\",float(r))\n",
    "print(\"K\\n\",K)\n",
    "print(\"dist\",dist.ravel())\n",
    "np.savez(OUT, K=K, dist=dist, rms=r, img_size=sz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob(os.path.join(\"calibration\",\"*.jpeg\")))\n",
    "os.makedirs(\"calibration_output\", exist_ok=True)\n",
    "\n",
    "for pth in paths:\n",
    "    im = cv2.imread(pth)\n",
    "    if im is None: \n",
    "        continue\n",
    "    c,i,_ = detect(im)\n",
    "    vis = im.copy()\n",
    "\n",
    "    if i is not None and len(c)>0:\n",
    "        for cc in c:\n",
    "            pts = cc.reshape(-1,2).astype(int)\n",
    "            for j in range(4):\n",
    "                p1 = tuple(pts[j])\n",
    "                p2 = tuple(pts[(j+1)%4])\n",
    "                cv2.line(vis, p1, p2, (0,255,0), 4)\n",
    "                cv2.circle(vis, p1, 8, (0,0,255), -1)\n",
    "\n",
    "    cv2.imwrite(os.path.join(\"calibration_output\", \"vis_\"+os.path.basename(pth)), vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_1390.jpeg', 'IMG_1391.jpeg', 'IMG_1392.jpeg', 'IMG_1394.jpeg', 'IMG_1395.jpeg', 'IMG_1397.jpeg', 'IMG_1398.jpeg', 'IMG_1399.jpeg', 'IMG_1401.jpeg', 'IMG_1402.jpeg', 'IMG_1406.jpeg', 'IMG_1407.jpeg', 'IMG_1409.jpeg', 'IMG_1410.jpeg', 'IMG_1411.jpeg', 'IMG_1413.jpeg', 'IMG_1417.jpeg', 'IMG_1419.jpeg', 'IMG_1420.jpeg', 'IMG_1421.jpeg', 'IMG_1427.jpeg', 'IMG_1429.jpeg', 'IMG_1432.jpeg', 'IMG_1434.jpeg', 'IMG_1436.jpeg', 'IMG_1437.jpeg', 'IMG_1439.jpeg', 'IMG_1440.jpeg', 'IMG_1442.jpeg', 'IMG_1444.jpeg', 'IMG_1446.jpeg', 'IMG_1447.jpeg', 'IMG_1449.jpeg', 'IMG_1450.jpeg', 'IMG_1451.jpeg', 'IMG_1452.jpeg', 'IMG_1453.jpeg', 'IMG_1454.jpeg', 'IMG_1456.jpeg', 'IMG_1457.jpeg', 'IMG_1459.jpeg', 'IMG_1460.jpeg', 'IMG_1461.jpeg', 'IMG_1462.jpeg', 'IMG_1463.jpeg', 'IMG_1464.jpeg', 'IMG_1465.jpeg', 'IMG_1466.jpeg', 'IMG_1467.jpeg', 'IMG_1468.jpeg']\n"
     ]
    }
   ],
   "source": [
    "tag_size = 0.06\n",
    "obj = np.array([\n",
    "    [0, 0, 0],\n",
    "    [tag_size, 0, 0],\n",
    "    [tag_size, tag_size, 0],\n",
    "    [0, tag_size, 0]\n",
    "], np.float32)\n",
    "\n",
    "paths = sorted(glob.glob(os.path.join(\"airpods\", \"*.jpeg\")))\n",
    "\n",
    "c2w_list = []\n",
    "img_names = []\n",
    "imgs = []\n",
    "\n",
    "for pth in paths:\n",
    "    img = cv2.imread(pth)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    corners, ids, _ = detect(img)\n",
    "    if ids is None or len(corners) == 0:\n",
    "        continue\n",
    "\n",
    "    uv = corners[0].reshape(4, 2).astype(np.float32)\n",
    "\n",
    "    success, rvec, tvec = cv2.solvePnP(obj, uv, K, dist)\n",
    "    if not success:\n",
    "        continue\n",
    "\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    Rt = R.T\n",
    "    t = tvec.reshape(3, 1)\n",
    "\n",
    "    c2w = np.hstack([Rt, -Rt @ t])\n",
    "\n",
    "    c2w_list.append(c2w)\n",
    "    img_names.append(os.path.basename(pth))\n",
    "    imgs.append(img)\n",
    "print(img_names)\n",
    "np.savez(\"calibration_output/poses_pnp.npz\",\n",
    "         c2ws=np.array(c2w_list, dtype=np.float32),\n",
    "         names=np.array(img_names),\n",
    "         K=K,\n",
    "         dist=dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────── <span style=\"font-weight: bold\">viser</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">(listening *:8090)</span> ───────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8090   │\n",
       "│   Websocket │ ws://localhost:8090     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────── \u001b[1mviser\u001b[0m \u001b[2m(listening *:8090)\u001b[0m ───────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8090   │\n",
       "│   Websocket │ ws://localhost:8090     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Generated share URL <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours, max <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> clients<span style=\"font-weight: bold\">)</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://action-disparity.share.viser.studio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Generated share URL \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours, max \u001b[1;36m16\u001b[0m clients\u001b[1m)\u001b[0m: \u001b[4;94mhttps://action-disparity.share.viser.studio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m130\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 29\u001b[0m\n\u001b[1;32m     18\u001b[0m     server\u001b[38;5;241m.\u001b[39mscene\u001b[38;5;241m.\u001b[39madd_camera_frustum(\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/cameras/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m         fov\u001b[38;5;241m=\u001b[39mfov,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m         image\u001b[38;5;241m=\u001b[39mimg[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import viser\n",
    "import time\n",
    "\n",
    "poses = np.load(\"calibration_output/poses_pnp.npz\", allow_pickle=True)\n",
    "c2ws = list(poses[\"c2ws\"])\n",
    "names = list(poses[\"names\"])\n",
    "\n",
    "server = viser.ViserServer(share=True)\n",
    "\n",
    "for idx, (c2w, name) in enumerate(zip(c2ws, names)):\n",
    "    img = cv2.imread(os.path.join(\"airpods\", name))\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    H, W = img.shape[:2]\n",
    "    fov = 2 * np.arctan2(H / 2.0, K[0, 0])\n",
    "\n",
    "    server.scene.add_camera_frustum(\n",
    "        f\"/cameras/{idx}\",\n",
    "        fov=fov,\n",
    "        aspect=W / float(H),\n",
    "        scale=0.01,\n",
    "        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "        position=c2w[:3, 3],\n",
    "        image=img[:, :, ::-1]\n",
    "    )\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "c2ws = []\n",
    "c2ws_all = list(poses[\"c2ws\"])\n",
    "H0 = W0 = None\n",
    "for idx, n in enumerate(names):\n",
    "    p = os.path.join(\"airpods\", n)\n",
    "    im = cv2.imread(p)\n",
    "    if im is None: \n",
    "        continue\n",
    "    if im.ndim == 2:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)\n",
    "    und = cv2.undistort(im, K, dist)\n",
    "    if H0 is None:\n",
    "        H0, W0 = und.shape[:2]\n",
    "        focal = float(K[0,0])\n",
    "    else:\n",
    "        if und.shape[:2] != (H0, W0):\n",
    "            und = cv2.resize(und, (W0, H0), interpolation=cv2.INTER_AREA)\n",
    "    imgs.append(und)\n",
    "    c2ws.append(c2ws_all[idx])\n",
    "\n",
    "imgs = np.stack(imgs, axis=0).astype(np.uint8)\n",
    "c2ws = np.array(c2ws, dtype=np.float32)\n",
    "\n",
    "N = len(imgs)\n",
    "n_train = int(0.9 * N)\n",
    "n_val = int(0.10 * N)\n",
    "\n",
    "images_train = imgs[:n_train]\n",
    "c2ws_train = c2ws[:n_train]\n",
    "\n",
    "images_val = imgs[n_train:n_train + n_val]\n",
    "c2ws_val = c2ws[n_train:n_train + n_val]\n",
    "\n",
    "images_test = imgs[n_train + n_val:]\n",
    "c2ws_test = c2ws[n_train + n_val:]\n",
    "\n",
    "np.savez(\n",
    "    \"calibration_output/my_nerf_data.npz\",\n",
    "    images_train=images_train,\n",
    "    c2ws_train=c2ws_train,\n",
    "    images_val=images_val,\n",
    "    c2ws_val=c2ws_val,\n",
    "    images_test=images_test,\n",
    "    c2ws_test=c2ws_test,\n",
    "    focal=focal\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
