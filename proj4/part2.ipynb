{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (100, 200, 200, 3) K[0,0] (fx) = 277.77777\n"
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = np.load(f\"lego_200x200.npz\")\n",
    "\n",
    "images_train = data[\"images_train\"] / 255.0\n",
    "c2ws_train = data[\"c2ws_train\"]\n",
    "images_val = data[\"images_val\"] / 255.0\n",
    "c2ws_val = data[\"c2ws_val\"]\n",
    "c2ws_test = data[\"c2ws_test\"]\n",
    "focal = data[\"focal\"]  \n",
    "\n",
    "N_train, H, W, _ = images_train.shape\n",
    "K = np.array([\n",
    "    [focal,    0.0,  W/2.0],\n",
    "    [0.0,      focal, H/2.0],\n",
    "    [0.0,      0.0,  1.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"Train set:\", images_train.shape, \"K[0,0] (fx) =\", K[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_hom(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        x = x[None, :]  \n",
    "    ones = np.ones((*x.shape[:-1], 1), dtype=x.dtype)\n",
    "    return np.concatenate([x, ones], axis=-1)\n",
    "\n",
    "\n",
    "def transform(T_4x4, x):\n",
    "    xh = _to_hom(x)                                    \n",
    "    y  = xh @ T_4x4.T                                  \n",
    "    return y[..., :3] / np.clip(y[..., 3:4], 1e-8, None)\n",
    "\n",
    "def pixel_to_camera(K, uv, s):\n",
    "    uv = np.asarray(uv, dtype=np.float32)\n",
    "    s  = np.asarray(s,  dtype=np.float32)\n",
    "\n",
    "    fx, fy = K[0,0], K[1,1]\n",
    "    cx, cy = K[0,2], K[1,2]\n",
    "\n",
    "    u = uv[..., 0]\n",
    "    v = uv[..., 1]\n",
    "\n",
    "    \n",
    "    if s.shape == ():\n",
    "        s = np.broadcast_to(s, u.shape)\n",
    "    else:\n",
    "        s = np.broadcast_to(s, u.shape)\n",
    "\n",
    "    X = (u - cx) / fx * s\n",
    "    Y = (v - cy) / fy * s\n",
    "    Z = s\n",
    "\n",
    "    return np.stack([X, Y, Z], axis=-1).astype(np.float32)\n",
    "\n",
    "\n",
    "def pixel_to_ray(K, c2w, uv):\n",
    "    \n",
    "    origin = c2w[:3, 3].astype(np.float32)\n",
    "\n",
    "    \n",
    "    x_c = pixel_to_camera(K, uv, s=1.0)                \n",
    "    \n",
    "    x_w = transform(c2w, x_c)                          \n",
    "\n",
    "    \n",
    "    d = x_w - origin\n",
    "    norm = np.linalg.norm(d, axis=-1, keepdims=True)\n",
    "    d = d / np.clip(norm, 1e-8, None)\n",
    "    \n",
    "    o = np.broadcast_to(origin, d.shape).astype(np.float32)\n",
    "    return o, d.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max |x - inv(inv(x))|: 2.0438067682704286e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "idx = np.random.randint(0, N_train)\n",
    "c2w = c2ws_train[idx]\n",
    "w2c = np.linalg.inv(c2w)\n",
    "\n",
    "pts_c = np.random.randn(5, 3).astype(np.float32)\n",
    "pts_w = transform(c2w, pts_c)\n",
    "pts_c_back = transform(w2c, pts_w)\n",
    "print(\"Max |x - inv(inv(x))|:\", np.max(np.abs(pts_c - pts_c_back)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaysData:\n",
    "    def __init__(self, images, K, c2ws):\n",
    "        \"\"\"\n",
    "        images: (N, H, W, 3)\n",
    "        K: (3, 3)\n",
    "        c2ws: (N, 4, 4)\n",
    "        \"\"\"\n",
    "        self.images = images.astype(np.float32)\n",
    "        self.K = K.astype(np.float32)\n",
    "        self.c2ws = c2ws.astype(np.float32)\n",
    "\n",
    "        self.N, self.H, self.W, _ = images.shape\n",
    "\n",
    "        xs = np.arange(self.W, dtype=np.int32)\n",
    "        ys = np.arange(self.H, dtype=np.int32)\n",
    "        grid_x, grid_y = np.meshgrid(xs, ys, indexing=\"xy\")  \n",
    "\n",
    "        uvs = np.stack([grid_x, grid_y], axis=-1) \n",
    "        uvs = np.tile(uvs[None,...], (self.N,1,1,1))  \n",
    "        self.uvs = uvs.reshape(-1, 2)  \n",
    "\n",
    "        \n",
    "        self.pixels = images.reshape(-1, 3)  \n",
    "\n",
    "        \n",
    "        img_ids = np.arange(self.N)\n",
    "        img_ids = np.repeat(img_ids, self.H*self.W)\n",
    "        self.img_ids = img_ids\n",
    "\n",
    "        self.total = len(self.uvs)\n",
    "                \n",
    "        self.rays_o = np.empty((self.total, 3), dtype=np.float32)\n",
    "        self.rays_d = np.empty((self.total, 3), dtype=np.float32)\n",
    "\n",
    "        \n",
    "        per_img_uvs = self.uvs.reshape(self.N, self.H * self.W, 2).astype(np.float32) + 0.5\n",
    "\n",
    "        offset = 0\n",
    "        for i in range(self.N):\n",
    "            \n",
    "            o, d = pixel_to_ray(self.K, self.c2ws[i], per_img_uvs[i])  \n",
    "            n = self.H * self.W\n",
    "            self.rays_o[offset:offset + n] = o\n",
    "            self.rays_d[offset:offset + n] = d\n",
    "            offset += n\n",
    "\n",
    "\n",
    "    def sample_rays(self, B):\n",
    "        idxs = np.random.randint(0, self.total, size=(B,))\n",
    "\n",
    "        \n",
    "        uv_int = self.uvs[idxs]  \n",
    "        uvs = uv_int.astype(np.float32) + 0.5\n",
    "\n",
    "        img_ids = self.img_ids[idxs]\n",
    "        c2w_batch = self.c2ws[img_ids]\n",
    "\n",
    "        rays_o = np.zeros((B, 3), dtype=np.float32)\n",
    "        rays_d = np.zeros((B, 3), dtype=np.float32)\n",
    "\n",
    "        for k in range(B):\n",
    "            o, d = pixel_to_ray(self.K, c2w_batch[k], uvs[k])\n",
    "            rays_o[k] = o\n",
    "            rays_d[k] = d\n",
    "\n",
    "        return rays_o, rays_d, self.pixels[idxs], uv_int\n",
    "\n",
    "def sample_along_rays(\n",
    "    rays_o,\n",
    "    rays_d,\n",
    "    n_samples=64,\n",
    "    near=2.0,\n",
    "    far=6.0,\n",
    "    perturb=True,\n",
    "    rng=None,\n",
    "    random=None,  \n",
    "):\n",
    "    \"\"\"\n",
    "    Uniform samples along rays in [near, far].\n",
    "\n",
    "    Backward + teacher-compatible behavior:\n",
    "    - If `random` is None (old calls): use `perturb` and RETURN (points, t_vals).\n",
    "    - If `random` is True/False (teacher calls): map to perturb and RETURN points only.\n",
    "\n",
    "    Args:\n",
    "      rays_o: (B,3)\n",
    "      rays_d: (B,3) normalized\n",
    "      n_samples, near, far: sampling config\n",
    "      perturb: (old API) stratified sampling when True\n",
    "      rng: np.random.Generator\n",
    "      random: (teacher API) if not None, overrides `perturb` and changes return type to only `points`\n",
    "\n",
    "    Returns:\n",
    "      - Old API (random is None): (points (B,n,3), t_vals (B,n))\n",
    "      - Teacher API (random is not None): points (B,n,3)\n",
    "    \"\"\"\n",
    "    B = rays_o.shape[0]\n",
    "\n",
    "    \n",
    "    use_perturb = perturb if random is None else bool(random)\n",
    "\n",
    "    if use_perturb:\n",
    "        \n",
    "        t_edges = np.linspace(near, far, n_samples + 1, dtype=np.float32)  \n",
    "        if rng is None:\n",
    "            rng = np.random.default_rng()\n",
    "        t_lower = t_edges[:-1]  \n",
    "        t_upper = t_edges[1:]   \n",
    "        r = rng.random((B, n_samples), dtype=np.float32)\n",
    "        t_vals = t_lower[None, :] + r * (t_upper - t_lower)[None, :]\n",
    "    else:\n",
    "        t_vals = np.linspace(near, far, n_samples, dtype=np.float32)[None, :].repeat(B, axis=0)\n",
    "\n",
    "    points = rays_o[:, None, :].astype(np.float32) + t_vals[..., None].astype(np.float32) * rays_d[:, None, :].astype(np.float32)\n",
    "\n",
    "    \n",
    "    if random is not None:\n",
    "        return points.astype(np.float32)\n",
    "\n",
    "    \n",
    "    return points.astype(np.float32), t_vals.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0]\n",
      " [  1   0]\n",
      " [  2   0]\n",
      " ...\n",
      " [197 199]\n",
      " [198 199]\n",
      " [199 199]]\n",
      "rays_o: (100, 3) rays_d: (100, 3) points: (100, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "print(dataset.uvs)\n",
    "B = 100\n",
    "rays_o, rays_d, pixels, uv_int = dataset.sample_rays(B)  \n",
    "\n",
    "\n",
    "\n",
    "points, t_vals = sample_along_rays(rays_o, rays_d, n_samples=64, near=2.0, far=6.0, perturb=True)\n",
    "\n",
    "print(\"rays_o:\", rays_o.shape, \"rays_d:\", rays_d.shape, \"points:\", points.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────── <span style=\"font-weight: bold\">viser</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">(listening *:8080)</span> ───────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8080   │\n",
       "│   Websocket │ ws://localhost:8080     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────── \u001b[1mviser\u001b[0m \u001b[2m(listening *:8080)\u001b[0m ───────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8080   │\n",
       "│   Websocket │ ws://localhost:8080     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Generated share URL <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours, max <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> clients<span style=\"font-weight: bold\">)</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://borderless-slices.share.viser.studio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Generated share URL \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours, max \u001b[1;36m16\u001b[0m clients\u001b[1m)\u001b[0m: \u001b[4;94mhttps://borderless-slices.share.viser.studio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000000000\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/p8xq1_zs2n5c2wcqjx945brm0000gn/T/ipykernel_83976/2391051616.py:10: DeprecationWarning: ViserServer.add_camera_frustum has been deprecated, use ViserServer.scene.add_camera_frustum instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_camera_frustum(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Viser server running. Interrupt the cell to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/p8xq1_zs2n5c2wcqjx945brm0000gn/T/ipykernel_83976/2391051616.py:23: DeprecationWarning: ViserServer.add_spline_catmull_rom has been deprecated, use ViserServer.scene.add_spline_catmull_rom instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_spline_catmull_rom(\n",
      "/var/folders/3m/p8xq1_zs2n5c2wcqjx945brm0000gn/T/ipykernel_83976/2391051616.py:28: DeprecationWarning: ViserServer.add_point_cloud has been deprecated, use ViserServer.scene.add_point_cloud instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_point_cloud(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">608</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m608\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViser server running. Interrupt the cell to stop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import viser\n",
    "import time\n",
    "\n",
    "\n",
    "server = viser.ViserServer(share=True)\n",
    "print(\"0000000000000\")\n",
    "\n",
    "for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n",
    "    print(i)\n",
    "    server.add_camera_frustum(\n",
    "        f\"/cameras/{i}\",\n",
    "        fov=2 * np.arctan2(H / 2, K[0, 0]),\n",
    "        aspect=W / H,\n",
    "        scale=0.15,\n",
    "        wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "        position=c2w[:3, 3],\n",
    "        image=image,\n",
    "    )\n",
    "print(\"1\")\n",
    "\n",
    "for i, (o, d) in enumerate(zip(rays_o, rays_d)):\n",
    "    print(i)\n",
    "    server.add_spline_catmull_rom(\n",
    "        f\"/rays/{i}\", positions=np.stack((o, o + d * 6.0), axis=0),\n",
    "    )\n",
    "\n",
    "\n",
    "server.add_point_cloud(\n",
    "    \"/samples\",\n",
    "    colors=np.zeros_like(points, dtype=np.float32).reshape(-1, 3),\n",
    "    points=points.reshape(-1, 3),\n",
    "    point_size=0.02,\n",
    ")\n",
    "\n",
    "print(\"Viser server running. Interrupt the cell to stop.\")\n",
    "while True:\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────── <span style=\"font-weight: bold\">viser</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">(listening *:8081)</span> ───────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8081   │\n",
       "│   Websocket │ ws://localhost:8081     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────── \u001b[1mviser\u001b[0m \u001b[2m(listening *:8081)\u001b[0m ───────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8081   │\n",
       "│   Websocket │ ws://localhost:8081     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Share URL requested!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Share URL requested!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Generated share URL <span style=\"font-weight: bold\">(</span>expires in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hours, max <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> clients<span style=\"font-weight: bold\">)</span>: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://dive-hidden.share.viser.studio</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Generated share URL \u001b[1m(\u001b[0mexpires in \u001b[1;36m24\u001b[0m hours, max \u001b[1;36m16\u001b[0m clients\u001b[1m)\u001b[0m: \u001b[4;94mhttps://dive-hidden.share.viser.studio\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/p8xq1_zs2n5c2wcqjx945brm0000gn/T/ipykernel_83976/3514010641.py:29: DeprecationWarning: ViserServer.add_camera_frustum has been deprecated, use ViserServer.scene.add_camera_frustum instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_camera_frustum(\n",
      "/var/folders/3m/p8xq1_zs2n5c2wcqjx945brm0000gn/T/ipykernel_83976/3514010641.py:40: DeprecationWarning: ViserServer.add_spline_catmull_rom has been deprecated, use ViserServer.scene.add_spline_catmull_rom instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_spline_catmull_rom(\n",
      "/var/folders/3m/p8xq1_zs2n5c2wcqjx945brm0000gn/T/ipykernel_83976/3514010641.py:43: DeprecationWarning: ViserServer.add_point_cloud has been deprecated, use ViserServer.scene.add_point_cloud instead. Alternatively, pin to `viser<0.2.0`.\n",
      "  server.add_point_cloud(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">608</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m608\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     43\u001b[0m server\u001b[38;5;241m.\u001b[39madd_point_cloud(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/samples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m     colors\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(points)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     46\u001b[0m     points\u001b[38;5;241m=\u001b[39mpoints\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     47\u001b[0m     point_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import viser, time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "\n",
    "\n",
    "uvs_start = 0\n",
    "uvs_end = 40_000\n",
    "sample_uvs = dataset.uvs[uvs_start:uvs_end] \n",
    "\n",
    "assert np.all(images_train[0, sample_uvs[:,1], sample_uvs[:,0]] == dataset.pixels[uvs_start:uvs_end])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indices_x = np.random.randint(low=100, high=200, size=100)\n",
    "indices_y = np.random.randint(low=0, high=100, size=100)\n",
    "indices = indices_x + (indices_y * 200)\n",
    "\n",
    "data = {\"rays_o\": dataset.rays_o[indices], \"rays_d\": dataset.rays_d[indices]}\n",
    "points = sample_along_rays(data[\"rays_o\"], data[\"rays_d\"], random=True)\n",
    "\n",
    "\n",
    "server = viser.ViserServer(share=True)\n",
    "for i, (image, c2w) in enumerate(zip(images_train, c2ws_train)):\n",
    "  print(i)\n",
    "  server.add_camera_frustum(\n",
    "    f\"/cameras/{i}\",\n",
    "    fov=2 * np.arctan2(H / 2, K[0, 0]),\n",
    "    aspect=W / H,\n",
    "    scale=0.15,\n",
    "    wxyz=viser.transforms.SO3.from_matrix(c2w[:3, :3]).wxyz,\n",
    "    position=c2w[:3, 3],\n",
    "    image=image\n",
    "  )\n",
    "for i, (o, d) in enumerate(zip(data[\"rays_o\"], data[\"rays_d\"])):\n",
    "  positions = np.stack((o, o + d * 6.0))\n",
    "  server.add_spline_catmull_rom(\n",
    "      f\"/rays/{i}\", positions=positions,\n",
    "  )\n",
    "server.add_point_cloud(\n",
    "    f\"/samples\",\n",
    "    colors=np.zeros_like(points).reshape(-1, 3),\n",
    "    points=points.reshape(-1, 3),\n",
    "    point_size=0.03,\n",
    ")\n",
    "\n",
    "while True:\n",
    "    time.sleep(0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class PosEnc(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional encoding for D-dimensional inputs.\n",
    "    Returns: [x, sin(2^k pi x), cos(2^k pi x)] for k=0..L-1 (applied per-dimension).\n",
    "    \"\"\"\n",
    "    def __init__(self, L: int, D: int):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "        self.D = D\n",
    "        \n",
    "        freqs = (2.0 ** torch.arange(L)) * math.pi\n",
    "        self.register_buffer(\"freqs\", freqs.float())\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (..., D)\n",
    "        returns: (..., D + 2*D*L)\n",
    "        \"\"\"\n",
    "        assert x.shape[-1] == self.D, f\"Expected last dim {self.D}, got {x.shape[-1]}\"\n",
    "        if self.L == 0:\n",
    "            return x\n",
    "        \n",
    "        xb = x.unsqueeze(-2) * self.freqs.view(-1, 1)   \n",
    "        s = torch.sin(xb)                               \n",
    "        c = torch.cos(xb)                               \n",
    "        \n",
    "        return torch.cat([x, s.reshape(*x.shape[:-1], -1), c.reshape(*x.shape[:-1], -1)], dim=-1)\n",
    "\n",
    "def pe_dim(D: int, L: int) -> int:\n",
    "    \"\"\"Output dimension of PE for D-dim input and L frequencies.\"\"\"\n",
    "    return D + 2 * D * L\n",
    "\n",
    "\n",
    "\n",
    "class NeRFMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    NeRF-style network:\n",
    "      - Trunk on PE(x) with skip at the middle.\n",
    "      - Density head: Linear(256->1) + ReLU.\n",
    "      - Color head: concat(feature, PE(d)) -> [Linear(256+dir_pe -> 128), ReLU, Linear(128->3), Sigmoid].\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 Lx: int = 10,     \n",
    "                 Ld: int = 4,      \n",
    "                 width: int = 256, \n",
    "                 depth: int = 8    \n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.Lx = Lx\n",
    "        self.Ld = Ld\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "\n",
    "        self.pe_x = PosEnc(L=Lx, D=3)\n",
    "        self.pe_d = PosEnc(L=Ld, D=3)\n",
    "\n",
    "        in_pos = pe_dim(3, Lx)   \n",
    "        in_dir = pe_dim(3, Ld)   \n",
    "\n",
    "        \n",
    "        layers1 = []\n",
    "        d = in_pos\n",
    "        half = depth // 2\n",
    "        for _ in range(half):\n",
    "            layers1 += [nn.Linear(d, width), nn.ReLU(inplace=True)]\n",
    "            d = width\n",
    "        self.trunk1 = nn.Sequential(*layers1)\n",
    "\n",
    "        \n",
    "        layers2 = []\n",
    "        d = width + in_pos  \n",
    "        for _ in range(depth - half):\n",
    "            layers2 += [nn.Linear(d, width), nn.ReLU(inplace=True)]\n",
    "            d = width\n",
    "        self.trunk2 = nn.Sequential(*layers2)\n",
    "\n",
    "        \n",
    "        self.sigma_head = nn.Sequential(\n",
    "            nn.Linear(width, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.feature_256 = nn.Linear(width, width)\n",
    "\n",
    "        \n",
    "        self.color_head = nn.Sequential(\n",
    "            nn.Linear(width + in_dir, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x_w: torch.Tensor, d_w: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x_w: (..., 3) world coords\n",
    "        d_w: (..., 3) view/ray direction (will be normalized)\n",
    "        Returns:\n",
    "           rgb:   (..., 3) in [0,1]\n",
    "           sigma: (..., 1) >= 0\n",
    "        \"\"\"\n",
    "        \n",
    "        d_w = F.normalize(d_w, dim=-1)\n",
    "\n",
    "        \n",
    "        x_enc = self.pe_x(x_w)   \n",
    "        d_enc = self.pe_d(d_w)   \n",
    "\n",
    "        \n",
    "        h1 = self.trunk1(x_enc)              \n",
    "        h  = torch.cat([h1, x_enc], dim=-1)  \n",
    "        h  = self.trunk2(h)                  \n",
    "\n",
    "        \n",
    "        sigma = self.sigma_head(h)           \n",
    "\n",
    "        \n",
    "        feat = self.feature_256(h)           \n",
    "        h_rgb = torch.cat([feat, d_enc], dim=-1)\n",
    "        rgb = self.color_head(h_rgb)         \n",
    "\n",
    "        return rgb, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 3]) torch.Size([32, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "nerf = NeRFMLP(Lx=10, Ld=4, width=256, depth=8)\n",
    "B, S = 32, 64\n",
    "x = torch.randn(B, S, 3)         \n",
    "d = torch.randn(B, S, 3)         \n",
    "rgb, sigma = nerf(x, d)\n",
    "print(rgb.shape, sigma.shape)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def volrend(sigmas: torch.Tensor, rgbs: torch.Tensor, step_size: float):\n",
    "    \"\"\"\n",
    "    Discrete volume rendering with constant step size (delta = step_size).\n",
    "\n",
    "    Args:\n",
    "      sigmas: (B, S, 1) density σ_i\n",
    "      rgbs:   (B, S, 3) color c_i in [0,1]\n",
    "      step_size: float Δ\n",
    "\n",
    "    Returns:\n",
    "      C: (B, 3) rendered RGB\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = 1.0 - torch.exp(-sigmas * step_size)            \n",
    "\n",
    "    \n",
    "    \n",
    "    cum = torch.cumsum((sigmas * step_size).squeeze(-1), dim=1)\n",
    "    \n",
    "    cum_exclusive = torch.cat(\n",
    "        [torch.zeros(cum.size(0), 1, device=cum.device, dtype=cum.dtype),\n",
    "         cum[:, :-1]], dim=1\n",
    "    )\n",
    "    T = torch.exp(-cum_exclusive).unsqueeze(-1)             \n",
    "\n",
    "    \n",
    "    weights = T * alpha                                     \n",
    "\n",
    "    \n",
    "    C = torch.sum(weights * rgbs, dim=1)                    \n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "sigmas = torch.rand((10, 64, 1))\n",
    "rgbs = torch.rand((10, 64, 3))\n",
    "step_size = (6.0 - 2.0) / 64\n",
    "rendered_colors = volrend(sigmas, rgbs, step_size)\n",
    "\n",
    "correct = torch.tensor([\n",
    "    [0.5006, 0.3728, 0.4728],\n",
    "    [0.4322, 0.3559, 0.4134],\n",
    "    [0.4027, 0.4394, 0.4610],\n",
    "    [0.4514, 0.3829, 0.4196],\n",
    "    [0.4002, 0.4599, 0.4103],\n",
    "    [0.4471, 0.4044, 0.4069],\n",
    "    [0.4285, 0.4072, 0.3777],\n",
    "    [0.4152, 0.4190, 0.4361],\n",
    "    [0.4051, 0.3651, 0.3969],\n",
    "    [0.3253, 0.3587, 0.4215]\n",
    "])\n",
    "assert torch.allclose(rendered_colors, correct, rtol=1e-4, atol=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(model, rays_o, rays_d, n_samples=64, near=2.0, far=6.0, device=\"cuda\", white_bg=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      rays_o, rays_d: (B,3) numpy or torch\n",
    "    Returns:\n",
    "      C: (B,3) torch float32 on device\n",
    "    \"\"\"\n",
    "    if not torch.is_tensor(rays_o):\n",
    "        rays_o = torch.from_numpy(rays_o)\n",
    "    if not torch.is_tensor(rays_d):\n",
    "        rays_d = torch.from_numpy(rays_d)\n",
    "    rays_o = rays_o.to(device).float()\n",
    "    rays_d = rays_d.to(device).float()\n",
    "\n",
    "    \n",
    "    t_vals = torch.linspace(near, far, n_samples, device=device).view(1, n_samples)  \n",
    "    step_size = (far - near) / n_samples\n",
    "\n",
    "    \n",
    "    pts = rays_o[:, None, :] + t_vals[..., None] * F.normalize(rays_d, dim=-1)[:, None, :]  \n",
    "\n",
    "    \n",
    "    dirs = F.normalize(rays_d, dim=-1)[:, None, :].expand_as(pts)  \n",
    "\n",
    "    \n",
    "    rgb, sigma = model(pts, dirs)  \n",
    "\n",
    "    \n",
    "    C = volrend(sigma, rgb, step_size=step_size)  \n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_image(model, K, c2w, H, W, n_samples=64, near=2.0, far=6.0, chunk=8192, device=\"cuda\"):\n",
    "    \n",
    "    xs = np.arange(W, dtype=np.float32)\n",
    "    ys = np.arange(H, dtype=np.float32)\n",
    "    grid_x, grid_y = np.meshgrid(xs, ys, indexing=\"xy\")  \n",
    "    uvs = np.stack([grid_x + 0.5, grid_y + 0.5], axis=-1).reshape(-1, 2)  \n",
    "\n",
    "    \n",
    "    o_all, d_all = pixel_to_ray(K, c2w, uvs)  \n",
    "\n",
    "    \n",
    "    colors = []\n",
    "    for i in range(0, H*W, chunk):\n",
    "        co = render_rays(model,\n",
    "                         o_all[i:i+chunk],\n",
    "                         d_all[i:i+chunk],\n",
    "                         n_samples=n_samples, near=near, far=far, device=device)\n",
    "        colors.append(co)\n",
    "    C = torch.cat(colors, dim=0).clamp(0, 1)  \n",
    "    img = (C.view(H, W, 3).cpu().numpy() * 255.0).astype(np.uint8)\n",
    "    return img\n",
    "def mse2psnr(mse: float) -> float:\n",
    "    return -10.0 * np.log10(max(mse, 1e-10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_nerf(\n",
    "    model,\n",
    "    dataset: RaysData,              \n",
    "    images_val, c2ws_val,           \n",
    "    K,\n",
    "    iters=1000,\n",
    "    rays_per_batch=10_000,\n",
    "    n_samples=64,\n",
    "    near=2.0,\n",
    "    far=6.0,\n",
    "    lr=5e-4,\n",
    "    snaps=(0,100,250,500,750,1000),\n",
    "    outdir=\"nerf_out\",\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mse_fn = torch.nn.MSELoss()\n",
    "\n",
    "    H, W = dataset.H, dataset.W\n",
    "    t0 = time.time()\n",
    "    val_psnr_hist = []\n",
    "\n",
    "    for it in range(iters + 1):\n",
    "\n",
    "        \n",
    "        rays_o_np, rays_d_np, rgbs_np, _ = dataset.sample_rays(rays_per_batch)  \n",
    "        target = torch.from_numpy(rgbs_np).to(device).float()  \n",
    "        \n",
    "        pred = render_rays(model, rays_o_np, rays_d_np,\n",
    "                           n_samples=n_samples, near=near, far=far, device=device)\n",
    "        loss = mse_fn(pred, target)\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "        if it % 10 == 0:\n",
    "            psnr = mse2psnr(float(loss.item()))\n",
    "            print(f\"[it {it:04d}] train MSE={float(loss):.6f} PSNR={psnr:.2f} dB\")\n",
    "\n",
    "            \n",
    "            val_psnrs = []\n",
    "            with torch.no_grad():\n",
    "                for i in range(min(len(images_val), 3)):  \n",
    "                    gt = (images_val[i] * 255.0).astype(np.uint8)\n",
    "                    pred_img = render_image(model, K, c2ws_val[i], H, W,\n",
    "                                            n_samples=n_samples, near=near, far=far, device=device)\n",
    "                    mse = np.mean(\n",
    "                        (pred_img.astype(np.float32)/255.0 - gt.astype(np.float32)/255.0) ** 2\n",
    "                    )\n",
    "                    val_psnrs.append(mse2psnr(mse))\n",
    "\n",
    "            mean_psnr = float(np.mean(val_psnrs))\n",
    "            val_psnr_hist.append((it, mean_psnr))\n",
    "\n",
    "            \n",
    "            xs = [t for t,_ in val_psnr_hist]\n",
    "            ys = [p for _,p in val_psnr_hist]\n",
    "            plt.figure(figsize=(5,3))\n",
    "            plt.plot(xs, ys, marker='o')\n",
    "            plt.xlabel(\"iter\"); plt.ylabel(\"Val PSNR (dB)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(outdir, \"val_psnr_curve.png\"), dpi=150)\n",
    "            plt.close()\n",
    "\n",
    "        \n",
    "        if it % 100 == 0 and it != 0:\n",
    "            torch.save({\n",
    "                \"it\": it,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"opt\": opt.state_dict(),\n",
    "                \"val_psnr_hist\": val_psnr_hist,\n",
    "            }, os.path.join(outdir, f\"ckpt_{it:06d}.pth\"))\n",
    "            torch.save({\n",
    "                \"it\": it,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"opt\": opt.state_dict(),\n",
    "                \"val_psnr_hist\": val_psnr_hist,\n",
    "            }, os.path.join(outdir, f\"ckpt_latest.pth\"))\n",
    "\n",
    "        \n",
    "        if it in snaps:\n",
    "            with torch.no_grad():\n",
    "                img_pred = render_image(model, K, c2ws_val[0], H, W,\n",
    "                                        n_samples=n_samples, near=near, far=far, device=device)\n",
    "            Image.fromarray(img_pred).save(os.path.join(outdir, f\"val0_it{it}.png\"))\n",
    "    print(f\"Done. time={time.time()-t0:.1f}s\")\n",
    "    return val_psnr_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_step_viser(dataset, model=None, K=None, n_rays=100, n_samples=64, near=2.0, far=6.0):\n",
    "    import viser\n",
    "    server = viser.ViserServer(share=True)\n",
    "\n",
    "    \n",
    "    for i, (image, c2w) in enumerate(zip(dataset.images, dataset.c2ws)):\n",
    "        server.add_camera_frustum(\n",
    "            f\"/cameras/{i}\",\n",
    "            fov=2 * np.arctan2(dataset.H / 2, dataset.K[0, 0]),\n",
    "            aspect=dataset.W / dataset.H,\n",
    "            scale=0.15,\n",
    "            wxyz=viser.transforms.SO3.from_matrix(c2w[:3,:3]).wxyz,\n",
    "            position=c2w[:3,3],\n",
    "            image=image,\n",
    "        )\n",
    "\n",
    "    \n",
    "    rays_o, rays_d, _, _ = dataset.sample_rays(n_rays)\n",
    "\n",
    "    \n",
    "    t_vals = np.linspace(near, far, n_samples, dtype=np.float32)  \n",
    "    points = rays_o[:, None, :] + t_vals[None, :, None] * (rays_d[:, None, :] / np.linalg.norm(rays_d, axis=-1, keepdims=True))\n",
    "    \n",
    "    for i, (o, d) in enumerate(zip(rays_o, rays_d)):\n",
    "        server.add_spline_catmull_rom(f\"/rays/{i}\", positions=np.stack([o, o + d * 6.0], axis=0))\n",
    "    server.add_point_cloud(\"/samples\", points=points.reshape(-1,3), colors=np.zeros_like(points.reshape(-1,3)), point_size=0.02)\n",
    "\n",
    "    print(\"Viser running; Ctrl/Cmd+C to stop.\")\n",
    "    import time\n",
    "    while True:\n",
    "        time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "\n",
    "@torch.no_grad()\n",
    "def render_test_sweep(model, K, c2ws_test, H, W, out_path=\"lego_sweep.gif\", fps=12, n_samples=64, near=2.0, far=6.0, device=\"cuda\"):\n",
    "    frames = []\n",
    "    for i, c2w in enumerate(c2ws_test):\n",
    "        img = render_image(model, K, c2w, H, W, n_samples=n_samples, near=near, far=far, device=device)\n",
    "        frames.append(img)\n",
    "    imageio.mimsave(out_path, frames, fps=fps)\n",
    "    print(f\"Saved sweep to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[it 0000] train MSE=0.085812 PSNR=10.66dB\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "[it 0010] train MSE=0.067687 PSNR=11.69dB\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "[it 0020] train MSE=0.064556 PSNR=11.90dB\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "[it 0030] train MSE=0.061440 PSNR=12.12dB\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "[it 0040] train MSE=0.054455 PSNR=12.64dB\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "[it 0050] train MSE=0.049760 PSNR=13.03dB\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "[it 0060] train MSE=0.041847 PSNR=13.78dB\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "[it 0070] train MSE=0.030773 PSNR=15.12dB\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "[it 0080] train MSE=0.025348 PSNR=15.96dB\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "[it 0090] train MSE=0.022865 PSNR=16.41dB\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "[it 0100] train MSE=0.019940 PSNR=17.00dB\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "[it 0110] train MSE=0.018684 PSNR=17.29dB\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "[it 0120] train MSE=0.016642 PSNR=17.79dB\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "[it 0130] train MSE=0.016450 PSNR=17.84dB\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "[it 0140] train MSE=0.014528 PSNR=18.38dB\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "[it 0150] train MSE=0.013922 PSNR=18.56dB\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "[it 0160] train MSE=0.013121 PSNR=18.82dB\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "[it 0170] train MSE=0.012875 PSNR=18.90dB\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "[it 0180] train MSE=0.012582 PSNR=19.00dB\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "[it 0190] train MSE=0.012482 PSNR=19.04dB\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "[it 0200] train MSE=0.010970 PSNR=19.60dB\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "[it 0210] train MSE=0.011521 PSNR=19.39dB\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "[it 0220] train MSE=0.011384 PSNR=19.44dB\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "[it 0230] train MSE=0.010941 PSNR=19.61dB\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "[it 0240] train MSE=0.010312 PSNR=19.87dB\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "[it 0250] train MSE=0.010724 PSNR=19.70dB\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "[it 0260] train MSE=0.009800 PSNR=20.09dB\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "[it 0270] train MSE=0.009878 PSNR=20.05dB\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "[it 0280] train MSE=0.009726 PSNR=20.12dB\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "[it 0290] train MSE=0.009585 PSNR=20.18dB\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "[it 0300] train MSE=0.009691 PSNR=20.14dB\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "[it 0310] train MSE=0.009736 PSNR=20.12dB\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "[it 0320] train MSE=0.008964 PSNR=20.47dB\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "[it 0330] train MSE=0.008837 PSNR=20.54dB\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "[it 0340] train MSE=0.008779 PSNR=20.57dB\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "[it 0350] train MSE=0.008151 PSNR=20.89dB\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "[it 0360] train MSE=0.009596 PSNR=20.18dB\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "[it 0370] train MSE=0.009197 PSNR=20.36dB\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "[it 0380] train MSE=0.007975 PSNR=20.98dB\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "[it 0390] train MSE=0.008915 PSNR=20.50dB\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "[it 0400] train MSE=0.008792 PSNR=20.56dB\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "[it 0410] train MSE=0.007681 PSNR=21.15dB\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "[it 0420] train MSE=0.007861 PSNR=21.04dB\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "[it 0430] train MSE=0.007901 PSNR=21.02dB\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "[it 0440] train MSE=0.007743 PSNR=21.11dB\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "[it 0450] train MSE=0.007558 PSNR=21.22dB\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "[it 0460] train MSE=0.007502 PSNR=21.25dB\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "[it 0470] train MSE=0.007233 PSNR=21.41dB\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "dataset = RaysData(images_train, K, c2ws_train)\n",
    "\n",
    "\n",
    "nerf = NeRFMLP(Lx=10, Ld=4, width=256, depth=8)\n",
    "\n",
    "\n",
    "val_hist = train_nerf(\n",
    "    model=nerf,\n",
    "    dataset=dataset,\n",
    "    images_val=images_val,\n",
    "    c2ws_val=c2ws_val,\n",
    "    K=K,\n",
    "    iters=1000,\n",
    "    rays_per_batch=10_000,  \n",
    "    n_samples=64,\n",
    "    near=2.0, far=6.0,\n",
    "    lr=5e-4,\n",
    "    snaps=(0,5,10,15,50,100,200,300,400,500,600,700,800,900,1000),\n",
    "    outdir=\"nerf_out\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "H, W = dataset.H, dataset.W\n",
    "pred0 = render_image(nerf, K, c2ws_val[0], H, W, n_samples=64, device=device)\n",
    "Image.fromarray(pred0).save(\"nerf_out/val0_final.png\")\n",
    "\n",
    "render_test_sweep(nerf, K, c2ws_test, H, W, out_path=\"nerf_out/lego_sweep.gif\", fps=12, n_samples=64, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
